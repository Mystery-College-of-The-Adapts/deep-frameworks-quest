{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a rough outline of what we'd like our graph to look like:\n",
    "![](https://i.imgur.com/5TedoE1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "- Each edge now has either a ```[None]``` or ```[]``` icon next to it. This represents the TensorFlow shape of the tensor flowing through that edge, with ```None``` representing a vector of any length, and ```[]``` representing a scalar.\n",
    "\n",
    "- The output of node ```d``` now flows into an update section, which contains Operations necessary to update Variables as well as pass data through to the TensorBoard summaries.\n",
    "\n",
    "- We have a separate name scope to contain our two Variables\n",
    "    - one to store the accumulated sum of our outputs\n",
    "    - the other to keep track of how many times we've run the graph. Since these two Variables operate outside of the flow of our main transformation, it makes sense to put them in a separate space.\n",
    "    \n",
    "- There is a name scope dedicated to our TensorBoard summaries which will hold our ```tf.scalar_summary``` Operations. We place them after the \"update\" section to ensure that the summaries are added after we update our Variables, otherwise things could run out of order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explicitly create the graph that we would like to use\n",
    "# instead of using the default graph\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.name_scope(\"variables\"):\n",
    "        # set trainable=False since we aren' training anything!\n",
    "        # Variable to keep track of how many times the graph has been run\n",
    "        global_step = tf.Variable(0, dtype=tf.int32, \n",
    "                                  trainable=False, \n",
    "                                  name=\"global_step\")\n",
    "        \n",
    "        # Variable that keeps track of sum of all output values over time\n",
    "        total_output = tf.Variable(0.0, dtype=tf.float32, \n",
    "                                   trainable=False, \n",
    "                                   name=\"total_output\")\n",
    "        \n",
    "    with tf.name_scope(\"transformation\"):\n",
    "        # Separate input layer\n",
    "        with tf.name_scope(\"input\"):\n",
    "            # Create input placeholder - takes in a vector\n",
    "            a = tf.placeholder(tf.float32, shape=[None], \n",
    "                               name=\"input_placeholder_a\")\n",
    "            \n",
    "        # Separate middle layer\n",
    "        with tf.name_scope(\"intermediate_layer\"):\n",
    "            b = tf.reduce_prod(a, name=\"product_b\")\n",
    "            c = tf.reduce_sum(a, name=\"sum_c\")\n",
    "            \n",
    "        # Separate output layer\n",
    "        with tf.name_scope(\"output\"):\n",
    "            output = tf.add(b, c, name=\"output\")\n",
    "            \n",
    "    with tf.name_scope(\"update\"):\n",
    "        # Increments the total_output Variable by the latest output\n",
    "        update_total = total_output.assign_add(output)\n",
    "        \n",
    "        # Increments the above 'global_step' variable,\n",
    "        # Should be run whenever the graph is run\n",
    "        increment_step = global_step.assign_add(1)\n",
    "    \n",
    "    with tf.name_scope(\"summaries\"):\n",
    "        avg = tf.div(update_total, tf.cast(increment_step, tf.float32),\n",
    "                    name=\"average\")\n",
    "        \n",
    "        # Creates summaries for output node\n",
    "        tf.summary.scalar(\"output_summary\", output)\n",
    "        tf.summary.scalar(\"total_summary\", update_total)\n",
    "        tf.summary.scalar(\"average_summary\", avg)\n",
    "        \n",
    "    with tf.name_scope(\"global_ops\"):\n",
    "        # Initialization Op\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        # Merge all summaries into one operation\n",
    "        merged_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running the graph\n",
    "sess = tf.Session(graph=graph)\n",
    "writer = tf.summary.FileWriter('./improved_graph', graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a Session started, let's initialize our Variables before doing anything else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_graph(input_tensor):\n",
    "    feed_dict = {a: input_tensor}\n",
    "    _, step, summary = sess.run([output, increment_step, \n",
    "                                 merged_summaries],\n",
    "                                feed_dict=feed_dict)\n",
    "    writer.add_summary(summary, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's actually sue it!\n",
    "run_graph([2, 8])\n",
    "run_graph([3, 1, 3, 3])\n",
    "run_graph([8])\n",
    "run_graph([1, 2, 3])\n",
    "run_graph([11, 4])\n",
    "run_graph([7, 3, 1])\n",
    "run_graph([6, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write teh summaries to disk with the ```tf.summary.flush()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/sfzjg4P.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
