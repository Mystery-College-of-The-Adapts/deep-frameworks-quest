{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "- In **Supervised Learning**, we **train an inference model** with an input dataset, along with the real or expected output for each example.\n",
    "\n",
    "- Although the inference models may vary significantly in the number of operations they use, and in the way they combine and the number of parameters they have; we always apply the same general structure for training them:\n",
    "\n",
    "![](https://i.imgur.com/cn4rR8x.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some generic scaffolding for the model code.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize variables/model parameters\n",
    "\n",
    "# define the training loop operations\n",
    "def inference(X):\n",
    "    # compute inference model over data X and return the result\n",
    "    \n",
    "def loss(X, Y):\n",
    "    # Compute loss over training data X and expected outputs Y\n",
    "    \n",
    "def inputs():\n",
    "    # Read/Generate input training data X and expected outputs Y\n",
    "    \n",
    "\n",
    "def train(total_loss):\n",
    "    # Train/adjust model parameters according to computed total loss\n",
    "    \n",
    "def evaluate(sess, X, Y):\n",
    "    # Evaluate the resulting training model\n",
    "    \n",
    "# Create a saver\n",
    "saver = tf.train.Saver()\n",
    "    \n",
    "# Launch the graph in a session, setup boilerplate\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    X, Y = inputs()\n",
    "    \n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    initial_step = 0\n",
    "    \n",
    "    # verify if we don't have a checkpoint saved already\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(__file__))\n",
    "    \n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        # Restores from checkpoint\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        initial_step = int(ckpt.model_checkpoint_path.rsplit('-', 1)[1]\n",
    "        \n",
    "    # actual training loop\n",
    "    training_steps = 10000\n",
    "    for step in range(initial_step, training_steps):\n",
    "        sess.run([train_op])\n",
    "        \n",
    "        # For debugging and learning purposes, see how the loss\n",
    "        # gets decremented through training steps\n",
    "        if step % 1000 == 0:\n",
    "            print(\"loss: \", sess.run([total_loss])\n",
    "            saver.save(sees, 'my_model', global_step=step)\n",
    "            \n",
    "    evaluate(sess, X, Y)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    saver.save(sess, 'my_model', global_step=training_steps)\n",
    "    sess.close() \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
